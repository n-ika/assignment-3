---
title: "Assignment 3"
author: "Nika Jurov"
date: "12/3/2018"
output: html_document
---

```{r include=FALSE}
library(devtools)
library(magrittr)
library(dplyr)
```

```{r include=FALSE}
source("functions3.R")
```


```{r include=FALSE}

devtools::install_github("ewan/stats_course", subdir="data/clark_judgments")

MOP_data <- clarkjudgments::acceptability %>%
            dplyr::filter(MOP == "MOP100")
```


* Dependent variable is **rating**. 
* Predictor is **language**.

## Question 1

```{r include = FALSE}
plot_MOP_hist <- ggplot2::ggplot(MOP_data, 
                                 ggplot2::aes(x=rating, 
                                              fill=language)) +
                 ggplot2::geom_histogram(
                                 alpha=0.4,
                                 bins = 50,
                                 position="identity")


# recode language to 0 and 1
MOP_linear <- MOP_data %>%
  dplyr::mutate(
    language_lin = ifelse(
      language == "adger-good", 1, 0
    ))


# linear model for MOP_data
lm_lin <- lm(rating ~ language_lin, data = MOP_linear)


# plot with dots for supposedly linear data
plot_linear_points <- ggplot2::ggplot(MOP_linear, 
                                      ggplot2::aes(y=rating, 
                                                   x=language_lin)) +
                                ggplot2::geom_point(
                                  alpha=0.1,
                                  colour="darkblue"
                                ) +
                                ggplot2::geom_abline(
                                  intercept = coef(lm_lin)[1],
                                  slope = coef(lm_lin)[2]
                                )
```


```{r echo=FALSE}
plot_MOP_hist
plot_linear_points
```


We can see clearly on the plots that we have two discrete categorial variables. This is also evident from inspecting the table of the data alone. The distribution of ratings is therefore dispersed according to either one value or the other (the language judged as "*good*" or "*bad*"). Thus, we obtain two vertical lines of two separate distributions that extend from 0 to 100 (0 being the lowest possible rating and 100 the highest possible rating). 

The dependent variable y (*rating*) does in fact change according to the predictor: we might be able to say that more of *bad* values are towards 0 than *good* and vice versa, that more *good* values are towards 100 that *bad*. We can even plot this with a line connecting the most dense distribution. However, there are still many values that do not behave as just stated and thus the Gaussian error would be too big for each distribution. It is visible from the histogram of both subsets (language is either good or bad) that ratings can be anywhere between 0 to 100.

Another problem for fitting this data into a linear model is also that there are absolutely no values below 0 and beyond 100. Because the most frequent values tend to be either around 0 or around 100 (but not below 0 and higher than 100), these are not Gaussian distributions. Finding the mean would make no sense here. 


## Question 2


### H1
                    
```{r}
# Permute the data under the H1 where
# the difference in means is 0 or somewhere close

coefficients_H1 <- rep(0, 9999)
for (i in 1:9999) {
          permuted_MOP <- MOP_data %>%
                    dplyr::mutate(
                    permuted_rating = 
                      sample(rating, dim(MOP_data)[1])
                    )
          coef_permuted <- coef(lm(permuted_rating ~ 
                                   language, 
                                   data = permuted_MOP))[2]
          coefficients_H1[i] <- coef_permuted
}

```


### H2

```{r}
# Filter the data according to the language value
good <- MOP_data %>%
              dplyr::filter(
              language == "adger-good"
                )
bad <- MOP_data %>%
              dplyr::filter(
              language == "adger-bad"
                )

# Find the observed SD values and store them in a vector
sd_good <- sd(good$rating)
sd_bad <- sd(bad$rating)
both_sd = c(sd_good, sd_bad)

# Store the observed mean difference
observed_mean_diff <- mean(good$rating) - mean(bad$rating)
```


```{r}
# The H2 permutation where difference in means is the same
# as observed mean difference and standard deviation is
# one of the two observed standard deviations
coefficients_H2 <- permute_for_h2(
                           observed_mean_diff, 
                           both_sd,
                           (dim(good)[1]/2),
                           (dim(bad)[1]/2),
                           0)
```


### Comparing the two sampling distributions


```{r include=FALSE}
plot_H1_H2 <- plot_permuted_data(coefficients_H1,
                                 coefficients_H2,
                                 1,
                                 c(-10,75))
```

```{r echo=FALSE}
plot_H1_H2
```




### H1 and H2 under the assumption of being closer to the observed data distribution

```{r}
# The H2 permutation where the mean for "good" is 100
# and the mean for "bad" is 0 and standard deviation is
# one of the two observed standard deviations.

# Additionally, define all values below 0 as 0
# and all values above 100 as 100.
coefficients_H3_adjusted <- permute_for_h2(
                           observed_mean_diff, 
                           both_sd,
                           (dim(good)[1]/2),
                           (dim(bad)[1]/2),
                           2)

# The H2 permutation where the difference in means
# is the same as the *observed difference in means*,
# standard deviation is one of the two observed 
# standard deviations.

# Additionally, define all values below 0 as 0
# and all values above 100 as 100.
coefficients_H3 <- permute_for_h2(
                           observed_mean_diff, 
                           both_sd,
                           (dim(good)[1]/2),
                           (dim(bad)[1]/2),
                           1)
```



For the purpose of making the simulated data more similar to what is observed, I now slightly change the data for Hypothesis 2. (I call it H3) I define the means for the two different groups as either `0` for `bad` and `100` for `good`. I obtain two distributions that are centered around 0 and 100. The standard deviations stay the same as before.

Additionally, I change the values that are below 0 to 0 and those that are above 100 to 100. I thus obtain a scale of ratings from 0 to 100, just like in the observed data.

There are now many values at 0 or at 100. This is similar to the observed distributions.
Now, if we look at the difference of the coeficients distributions, we see that beta 1 for H3 is a bit higher (around 80). This is due to different two new means (0 and 100). I have also tried to have the same mean difference as before and the result is similar but less clear, so I have decided to keep the means as 0 and 100.

```{r include = FALSE}
plot_H1_H3 <- plot_permuted_data(coefficients_H1,
                                 coefficients_H3,
                                 1,
                                 c(-10,95))

plot_H1_H3_adjusted <- plot_permuted_data(coefficients_H1,
                                 coefficients_H3_adjusted,
                                 1,
                                 c(-10,95))
```


```{r echo=FALSE}
plot_H1_H3
plot_H1_H3_adjusted
```

If I look at the distribution of permuted coefficients, I could say that there is indeed a big difference betwen H1 (which supposes 0 difference in the mean for the language being good or bad) and h2 (a big difference in means). Under the assumption that the data is normally distributed for H2, I could conclude that indeed this linear model is valid and shows that the dependent variable y (`rating`) changes according to the predictor x (`language`).

However, looking at the histogram above and seeing the plot of the H3, I see clearly that the distribution of the two groups is not normal. The mean can no longer be at 0 or 100, because I changed the negative values to 0 and the values above 100 to 100. The distributions are no longer centered around their means. I can calculate new means with `r`, but this is useless, just as supposing that the distributions are normal. The most values should be centered around their means, but they are not: they are either 0 or 100.

The serious risk here is, I think, that I am presupposing these distributions are normal and that their values will be centered around the calculated means. I then fit the data into a linear model and confirm that indeed, there is a big mean difference and the `language` has an effect on the `rating`. This is only partially true: in the observed data, we can see that even grammatically bad sentences are sometimes judged as good and can obtain any score between 0-100. Most values are at 0, but 0 is not the mean of the data. It cannot be, as is is the lowest value possible (rating numbers have to be limited somehow, here 1 probably means completely unacceptable/ungrammatical). 
For each permuted data, beta 1 is calculated on the wrongly defined means. Therefore, these results are wrong too.


## Question 3

### H1

```{r}
# H1 with only 3 observations for each language
# type, taken from the real data
coefficients_H1_3obs <- rep(0, 9999)
for (i in 1:9999) {
          permuted_MOP <- MOP_data %>%
                    dplyr::mutate(
                    permuted_rating = 
                      sample(rating, dim(MOP_data)[1])
                    )
          permuted_MOP_3obs <- permuted_MOP %>% 
                    dplyr::group_by(language) %>%
                    dplyr::sample_n(3) %>%
                    dplyr::ungroup()
          
          
          coef_permuted <- coef(lm(permuted_rating ~ 
                                   language, 
                                   data = permuted_MOP_3obs))[2]
          coefficients_H1_3obs[i] <- coef_permuted
}

```


### H2

```{r}
# H2 with mean for "good" as 100 and mean for
# "bad" as 0, values are adjusted to resemble
# the real data more
coefficients_H2_3obs_adjusted <- permute_for_h2(
                           observed_mean_diff, 
                           both_sd,
                           3,
                           3,
                           2)

# H2 with the difference of the means of two groups
# that is the same as the observed mean difference
# and the values are adjusted
coefficients_H2_3obs <- permute_for_h2(
                           observed_mean_diff, 
                           both_sd,
                           3,
                           3,
                           1)
```



```{r include = FALSE}
plot_H1_H2_3obs_adjusted <- plot_permuted_data(coefficients_H1_3obs,
                                 coefficients_H2_3obs_adjusted,
                                 0.3,
                                 c(-130,150))

plot_H1_H2_3obs <- plot_permuted_data(coefficients_H1_3obs,
                                 coefficients_H2_3obs,
                                 0.3,
                                 c(-130,150))
```

```{r echo=FALSE}
plot_H1_H2_3obs_adjusted
plot_H1_H2_3obs
```

Still supposing that my data is normal, I now have much more difficulties in concluding that the language has an effect on the rating. For `plot_H1_H2_3obs_adjusted` (which has the mean 0 for one distribution, 100 for the other, as well as the values below 0 and above 100 adjusted), the H1 beta 1 coefficient is centered around 0 as before, but the variance is much larger. The H2 beta 1 coefficient is centered quite far away from 0, but the two distributions overlap.

If I chose the means for H2 according to the difference of the observed means difference, the two disctributions superpose even more (`plot_H1_H2_3obs`). The values below 0 are set to 0 and those above 100 to 100. It is now much less evident if the language has any influence on the rating.