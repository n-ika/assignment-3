---
title: "Assignment 3"
author: "Nika Jurov"
date: "12/3/2018"
output: html_document
---

```{r include=FALSE}
library(devtools)
library(magrittr)
library(dplyr)

devtools::install_github("ewan/stats_course", subdir="data/clark_judgments")

MOP_data <- clarkjudgments::acceptability %>%
            dplyr::filter(MOP == "MOP100")
```

* Dependent variable is **rating**. 
* Predictor is **language**.

## Question 1

```{r}
plot_MOP_hist <- ggplot2::ggplot(MOP_data, 
                                 ggplot2::aes(x=rating, 
                                              fill=language)) +
                                 ggplot2::geom_histogram(
                                   alpha=0.4, position="identity")


MOP_linear <- MOP_data %>%
              dplyr::mutate(
                language_lin = ifelse(
                  language == "adger-good", 1, 0
                )
              )

lm_lin <- lm(rating ~ language_lin, data = MOP_linear)
coef(lm_lin)[1]



plot_linear_points <- ggplot2::ggplot(MOP_linear, 
                                ggplot2::aes(y=rating, 
                                             x=language_lin)) +
                                ggplot2::geom_point(
                                  alpha=0.1,
                                  colour="darkblue"
                                ) +
        ggplot2::geom_abline(
          intercept = coef(lm_lin)[1],
          slope = coef(lm_lin)[2]
        )

plot_MOP_hist
plot_linear_points
```


We can see clearly on the plots that we have two discrete categorial variables. This is also evident from inspecting the table of the data alone. The distribution of ratings is therefore dispersed according to either one value or the other (the language judged as "*good*" or "*bad*"). Thus, we obtain two vertical lines of two separate distributions that extend from 0 to 100 (0 being the lowest possible rating and 100 the highest possible rating). 

The dependent variable y (*rating*) does in fact change according to the predictor: we might be able to say that more of *bad* values are towards 0 than *good* and vice versa, that more *good* values are towards 100 that *bad*. We can even plot this with a line connecting the most dense distribution. However, there are still many values that do not behave as just stated and thus the Gaussian error would be too big for each distribution. It is visible from the histogram of both subsets (language is either good or bad) that ratings can be anywhere between 0 to 100.

Another problem for fitting this data into a linear model is also that there are absolutely no values below 0 and beyond 100. Because the most frequent values tend to be either around 0 or around 100 (but not below 0 and higher than 100), these are not Gaussian distributions. Finding the mean would make no sense here. 


## Question 2

* ENA

**H1**
                    
```{r}
#nic ==> mn1 = mn2
#permutation test: 9999 times two distributions that have 0 difference between the means
#for N:...
permuted_MOP <- MOP_data %>%
                    dplyr::mutate(
                    permuted_rating = 
                      sample(rating, dim(MOP_data)[1])
                    )
good <- permuted_MOP %>%
              dplyr::filter(
              language == "adger-good"
                )
bad <- permuted_MOP %>%
              dplyr::filter(
              language == "adger-bad"
                )
mean_good <- mean(good$permuted_rating)
mean_bad <- mean(bad$permuted_rating)
mn_diff <- mean_good - mean_bad

permuted_coef <- coef(lm(rating ~ language))[2]
#v vektor

```


**H2**

```{r}
# mn1 - mn2 = 60
# PERMUTE
sd1 <- sd(good$permuted_rating)
sd2 <- sd(bad$permuted_rating)
mn1 <- sample(0:100, 1)
mn2 <- mn1 - 60
  
# TO NE GRE TAK
group1 <- MOP_data %>%
              #dplyr::filter(PORPRAVI?!) %>%
              dplyr::mutate(
                fake_good_ranking = 
                  rnorm(n = (dim(MOP_data)[1]/2), 
                        mean = mn1, sd = sd1))
                
group1 <- MOP_data %>%
              #dplyr::filter(PORPRAVI?!) %>%
              dplyr::mutate(
                fake_bad_ranking = 
                rnorm(n = (dim(MOP_data)[1]/2), 
                      mean = mn2, sd = sd2))

#KODIRAJ V 0 in 1 ali 1,-1
fake_coef <- coef(lm(rating ~ language))[2]

#daj v vektor

```

```{r}
# predstavi vse na istem plotu
# ggplot2::ggplot()
```


* DVA

```{r}
# odrezi vrednosti < 0 in > 100
# pokazi razliko med obema distrib.
```

Ce sta distribuciji blize temu, kar opazimo v resnicnih podatkih, potem to ni vec normalen zakon/Gauss, ker preprosto nimamo srednje vrednosti, ki centrira vse vrednosti naokoli z neko razliko. Imamo veliko nicel in veliko stotk, malo po in pred tem. Ce to vzamemo kot nrm. zakon, potem sklepamo, da so vrednosti tudi naokoli 0 in 100. Srednja vrednost zagotovo ne bo tam, kjer jo bomo ocenili glede na ocenjevanje, ce vzamemo to got gaussovsko distribucijo. Ja, je riziko


## Question 3

```{r}
# 3 observations only
# ja zagotovo mora biti popolnoma izkrivljeno
```

